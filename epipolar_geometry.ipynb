{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Import necessary dependecies\n",
    "from pathlib import Path\n",
    "from lightglue import LightGlue, LightGlue_custom, SuperPoint, SuperGlue, SIFT\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c = img1.shape[0], img1.shape[1]\n",
    "    draw_size1 = int(np.max([np.ceil(0.003 * np.shape(img1)[0]), 1]))\n",
    "    draw_size2 = int(np.max([np.ceil(0.003 * np.shape(img2)[0]), 1]))\n",
    "    draw_size3 = int(np.max([0.5 * draw_size1, 1]))\n",
    "    \n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        color = tuple([0, 255, 0])\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv.line(img1, (x0,y0), (x1,y1), color,draw_size3)\n",
    "        img1 = cv.circle(img1,tuple(pt1),draw_size1,color,-1)\n",
    "        img2 = cv.circle(img2,tuple(pt2),draw_size2,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "def draw_inlier_points(img1,img2,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    color = [0, 0 ,255]\n",
    "    draw_size1 = int(np.max([np.ceil(0.003 * np.shape(img1)[0]), 1]))\n",
    "    draw_size2 = int(np.max([np.ceil(0.003 * np.shape(img2)[0]), 1]))\n",
    "\n",
    "    for pt1,pt2 in zip(pts1,pts2):\n",
    "        img1 = cv.circle(img1,tuple(pt1),draw_size1,tuple(color),-1)\n",
    "        img2 = cv.circle(img2,tuple(pt2),draw_size2,tuple(color),-1)\n",
    "    return img1,img2\n",
    "\n",
    "def draw_outlier_points(img,pts):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    img = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "    color = [255, 0 ,0]\n",
    "    draw_size = int(np.max([np.ceil(0.003 * np.shape(img)[0]), 1]))\n",
    "\n",
    "    for pt in pts:\n",
    "        img = cv.circle(img,tuple(pt),draw_size,tuple(color),-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "matcher_features = \"superpoint\"\n",
    "ransacThresh=7\n",
    "ransacConf=0.99\n",
    "images = Path(\"assets\")\n",
    "img1_name = \"sacre_coeur1.jpg\"\n",
    "img2_name = \"sacre_coeur2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "\n",
    "if matcher_features == \"superpoint\":\n",
    "    extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "elif matcher_features == \"sift\":\n",
    "    extractor = SIFT(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "img1 = load_image(images / img1_name)\n",
    "img2 = load_image(images / img2_name)\n",
    "\n",
    "# image1 = load_image(images / \"sacre_coeur2.jpg\")\n",
    "setup = {\n",
    "            'matcher_model':  LightGlue(features=matcher_features).eval().to(device),\n",
    "            'matcher_name': \"LightGlue\",\n",
    "            }\n",
    "\n",
    "# Load\n",
    "matcher = setup['matcher_model']\n",
    "matcher_name = setup['matcher_name']\n",
    "\n",
    "# Extract features\n",
    "feats0 = extractor.extract(img1.to(device))\n",
    "feats1 = extractor.extract(img2.to(device))\n",
    "\n",
    "# Match features with matcher\n",
    "matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "feats0, feats1, matches01 = [\n",
    "    rbd(x) for x in [feats0, feats1, matches01]\n",
    "]  # remove batch dimension\n",
    "\n",
    "# Identify matched keypoints\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "pts1 = np.int32(m_kpts0)\n",
    "pts2 = np.int32(m_kpts1)\n",
    "\n",
    "F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_RANSAC, ransacReprojThreshold=ransacThresh, confidence=ransacConf)\n",
    "\n",
    "\n",
    "img1 = cv.imread('assets/' + img1_name, cv.IMREAD_GRAYSCALE) #trainimage # left image\n",
    "img2 = cv.imread('assets/' + img2_name, cv.IMREAD_GRAYSCALE) #trainimage # right image\n",
    "\n",
    "if mask is None:\n",
    "    kpts0 = kpts0.int()\n",
    "    kpts0 = kpts0.numpy()\n",
    "    kpts1 = kpts1.int()\n",
    "    kpts1 = kpts1.numpy()\n",
    "    pts1_outlier = kpts0\n",
    "    pts2_outlier = kpts1\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    img9 = draw_outlier_points(img1, pts1_outlier)\n",
    "    img11 = draw_outlier_points(img2, pts2_outlier)    \n",
    "\n",
    "else:\n",
    "    pts1_outlier = np.int32(pts1[mask.ravel()==0])\n",
    "    pts2_outlier = np.int32(pts2[mask.ravel()==0])\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "\n",
    "    # Find epilines corresponding to points in right image (second image) and\n",
    "    img3 = draw_outlier_points(img1, pts1_outlier)\n",
    "    img4 = draw_outlier_points(img2, pts2_outlier)\n",
    "\n",
    "    # drawing its lines on left image\n",
    "    lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "    lines1 = lines1.reshape(-1,3)\n",
    "    img5,img6 = drawlines(img3,img4,lines1,pts1,pts2)\n",
    "    # Find epilines corresponding to points in left image (first image) and\n",
    "    # drawing its lines on right image\n",
    "    lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "    lines2 = lines2.reshape(-1,3)\n",
    "    img7,img8 = drawlines(img4,img3,lines2,pts2,pts1)\n",
    "\n",
    "    img9,img10 = draw_inlier_points(img5,img6,pts1,pts2)\n",
    "    img11,img12 = draw_inlier_points(img7,img8,pts2,pts1)\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(img9)\n",
    "plt.subplot(122),plt.imshow(img11)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
