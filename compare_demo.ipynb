{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of SuperGlue and LightGlue Demo\n",
    "In this notebook we match two pairs of images using SuperGlue and LightGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependecies\n",
    "from pathlib import Path\n",
    "from lightglue import LightGlue, LightGlue_custom, SuperPoint, SuperGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "images = Path(\"assets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SuperPoint Extractor and Images for Matching\n",
    "As of now, the SuperGlue matcher only supports SuperPoint. Changes needed to support different input dimensional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "\n",
    "# Configs\n",
    "matcher_features = \"superpoint\"\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "image0 = load_image(images / \"sacre_coeur1.jpg\")\n",
    "image1 = load_image(images / \"sacre_coeur2.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LightGlue Matcher\n",
    "The top image shows the matches, while the bottom image shows the detected points pruned across layers.\n",
    "For pairs with significant viewpoint- and illumination changes, LightGlue can exclude a lot of points early in the matching process (red points), which significantly reduces the inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {\n",
    "            'matcher_model': LightGlue(features=matcher_features).eval().to(device),\n",
    "            'matcher_name': \"LightGlue\",\n",
    "            }\n",
    "\n",
    "# Load\n",
    "matcher = setup['matcher_model']\n",
    "matcher_name = setup['matcher_name']\n",
    "\n",
    "# Extract features\n",
    "feats0 = extractor.extract(image0.to(device))\n",
    "feats1 = extractor.extract(image1.to(device))\n",
    "\n",
    "# Match features with matcher\n",
    "matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "feats0, feats1, matches01 = [\n",
    "    rbd(x) for x in [feats0, feats1, matches01]\n",
    "]  # remove batch dimension\n",
    "\n",
    "# Identify matched keypoints\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "conf_threshold = matcher.default_conf[\"filter_threshold\"] # Min confidence threshold of matcher\n",
    "# conf_threshold = 0\n",
    "valid0 = (matches01['matching_scores0'] >  conf_threshold)\n",
    "valid1 = (matches01['matching_scores1'] >  conf_threshold)\n",
    "matching_num0 = sum(valid0.long())\n",
    "matching_num1 = sum(valid1.long())\n",
    "mconf0 = matches01['matching_scores0'][valid0]\n",
    "mconf1 = matches01['matching_scores1'][valid1]\n",
    "\n",
    "# Ensure consistency of matches\n",
    "sum_mconf0 = sum(mconf0)\n",
    "sum_mconf1 = sum(mconf1)\n",
    "try:\n",
    "    assert torch.round(sum_mconf0, decimals=3) == torch.round(sum_mconf1, decimals=3)\n",
    "except:\n",
    "    print(\"0 points met confidence threshold!\")\n",
    "assert matching_num0 == matching_num1\n",
    "\n",
    "# Calculate norm-score and match-prop\n",
    "num_kpts0 = len(kpts0)\n",
    "num_kpts1 = len(kpts1)\n",
    "matching_score = sum_mconf0 / matching_num0\n",
    "match_prop = matching_num0 / min(num_kpts0, num_kpts1)\n",
    "\n",
    "# Plot primary\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "label_text = [\n",
    "                matcher_name + \" with \" + list(matcher.features.keys())[0],\n",
    "                'Keypoints: {}:{}'.format(num_kpts0, num_kpts1),\n",
    "                'Matches: {}'.format(matching_num0),\n",
    "                'norm-score: {:.4f}'.format(matching_score),\n",
    "                'match-prop: {:.4f}'.format(match_prop), \n",
    "                'matching-num: {:4f}'.format(matching_num0),\n",
    "                'conf-thresh: {:4f}'.format(conf_threshold)\n",
    "            ]\n",
    "text_pos = [0.01, 0.99]\n",
    "for labels in label_text:\n",
    "    viz2d.add_text(0, text=labels, pos=text_pos, fs=15)\n",
    "    text_pos[1] = text_pos[1] - 0.05\n",
    "\n",
    "# Plot secondary\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=6)\n",
    "label_text_sec =    [\n",
    "                    'Detected Points',\n",
    "                    'Stop after {} layers'.format(matches01[\"stop\"]),\n",
    "                    'Colors indicate respective layers'\n",
    "                    ]\n",
    "text_pos = [0.01, 0.99]\n",
    "for labels in label_text_sec:\n",
    "    viz2d.add_text(0, text=labels, pos=text_pos, fs=15)\n",
    "    text_pos[1] = text_pos[1] - 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SuperGlue Matcher\n",
    "The top image shows the matches, while the bottom image shows the detected SuperPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Matcher\n",
    "setup = {\n",
    "            'matcher_model': SuperGlue(features=matcher_features).eval().to(device),\n",
    "            'matcher_name': \"SuperGlue\",\n",
    "            }\n",
    "\n",
    "# Load\n",
    "matcher = setup['matcher_model']\n",
    "matcher_name = setup['matcher_name']\n",
    "\n",
    "# Extract features\n",
    "feats0 = extractor.extract(image0.to(device))\n",
    "feats1 = extractor.extract(image1.to(device))\n",
    "\n",
    "# Match features with matcher\n",
    "matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "feats0, feats1, matches01 = [\n",
    "    rbd(x) for x in [feats0, feats1, matches01]\n",
    "]  # remove batch dimension\n",
    "\n",
    "# Identify matched keypoints\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "conf_threshold = matcher.default_conf[\"filter_threshold\"] # Min confidence threshold of matcher\n",
    "valid0 = (matches01['matching_scores0'] >  conf_threshold)\n",
    "valid1 = (matches01['matching_scores1'] >  conf_threshold)\n",
    "matching_num0 = sum(valid0.long())\n",
    "matching_num1 = sum(valid1.long())\n",
    "mconf0 = matches01['matching_scores0'][valid0]\n",
    "mconf1 = matches01['matching_scores1'][valid1]\n",
    "\n",
    "# Ensure consistency of matches\n",
    "sum_mconf0 = sum(mconf0)\n",
    "sum_mconf1 = sum(mconf1)\n",
    "try:\n",
    "    assert torch.round(sum_mconf0, decimals=3) == torch.round(sum_mconf1, decimals=3)\n",
    "except:\n",
    "    print(\"0 points met confidence threshold!\")\n",
    "assert matching_num0 == matching_num1\n",
    "\n",
    "# Calculate norm-score and match-prop\n",
    "num_kpts0 = len(kpts0)\n",
    "num_kpts1 = len(kpts1)\n",
    "matching_score = sum_mconf0 / matching_num0\n",
    "match_prop = matching_num0 / min(num_kpts0, num_kpts1)\n",
    "\n",
    "# Plot primary\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "label_text = [\n",
    "                matcher_name + \" with \" + list(matcher.features.keys())[0],\n",
    "                'Keypoints: {}:{}'.format(num_kpts0, num_kpts1),\n",
    "                'Matches: {}'.format(matching_num0),\n",
    "                'norm-score: {:.4f}'.format(matching_score),\n",
    "                'match-prop: {:.4f}'.format(match_prop), \n",
    "                'matching-num: {:4f}'.format(matching_num0),\n",
    "                'conf-thresh: {:4f}'.format(conf_threshold)\n",
    "            ]\n",
    "text_pos = [0.01, 0.99]\n",
    "for labels in label_text:\n",
    "    viz2d.add_text(0, text=labels, pos=text_pos, fs=15)\n",
    "    text_pos[1] = text_pos[1] - 0.05\n",
    "\n",
    "# Plot secondary\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=\"b\", ps=15)\n",
    "viz2d.add_text(0, f'Detected Points', fs=15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
